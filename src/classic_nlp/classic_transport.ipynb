{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7750490f",
   "metadata": {},
   "source": [
    "# Fabricating transportability issue by training and predicting on different data - leave one country out for training and use it for prediction. \n",
    "References: <br>\n",
    "zhou 2023 circumstances preceding female firearm suicide https://mental.jmir.org/2023/1/e49359/ <br>\n",
    "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34 <br>\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c1ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "import statsmodels.api as sm\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692059d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5401a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/phmrc/phmrc_adult_tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38338965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "json_file_path = '../../src/classic_nlp/cod_embeddings.json'\n",
    "\n",
    "# Read the JSON file and load it into a dictionary\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    cod_embeddings = json.load(json_file)\n",
    "\n",
    "# Convert keys to integers\n",
    "cod_embeddings = {int(key): value for key, value in cod_embeddings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539e4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = list(df['site'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07d93b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# Read in CSV files and store in dictionary\n",
    "train_excluded_dict = {}\n",
    "for region in regions:\n",
    "    file_path = f'../../data/train_test_val/train_ex_{region.lower()}.csv'\n",
    "    train_excluded_dict[region] = pd.read_csv(file_path)\n",
    "    \n",
    "# assign training data df names\n",
    "train_ex_ap = train_excluded_dict['ap']\n",
    "train_ex_dar = train_excluded_dict['dar']\n",
    "train_ex_pemba = train_excluded_dict['pemba']\n",
    "train_ex_mexico = train_excluded_dict['mexico']\n",
    "train_ex_bohol = train_excluded_dict['bohol']\n",
    "train_ex_up = train_excluded_dict['up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f19503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test / val\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "test_dict = {}\n",
    "val_dict = {}\n",
    "\n",
    "# Read in test and validation CSV files and store in dictionaries\n",
    "for region in regions:\n",
    "    test_file_path = f'../../data/train_test_val/test_{region}.csv'\n",
    "    val_file_path = f'../../data/train_test_val/val_{region}.csv'\n",
    "    \n",
    "    test_dict[region] = pd.read_csv(test_file_path)\n",
    "    val_dict[region] = pd.read_csv(val_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea8b828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign test and val data df names\n",
    "test_ap = test_dict['ap']\n",
    "test_dar = test_dict['dar']\n",
    "test_pemba = test_dict['pemba']\n",
    "test_mexico = test_dict['mexico']\n",
    "test_bohol = test_dict['bohol']\n",
    "test_up = test_dict['up']\n",
    "\n",
    "val_ap = val_dict['ap']\n",
    "val_dar = val_dict['dar']\n",
    "val_pemba = val_dict['pemba']\n",
    "val_mexico = val_dict['mexico']\n",
    "val_bohol = val_dict['bohol']\n",
    "val_up = val_dict['up']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da494168",
   "metadata": {},
   "source": [
    "## Define functions for classic nlp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05098ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_embedding(prediction_string):\n",
    "    '''\n",
    "    takes list of strings and returns a list of associated integer embeddings using the cod_embedding dict\n",
    "    '''\n",
    "    \n",
    "    result = list(map(lambda x: next(key for key, value in cod_embeddings.items() if value == x), prediction_string))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa0f423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(training, testing):\n",
    "    '''\n",
    "    accepts pandas dataframes with training and testing data for the same region.\n",
    "    splits Y and X and returns 4 vectors, two each for training and testing. \n",
    "    '''\n",
    "    \n",
    "    Test_X = testing['tags']\n",
    "    Test_Y = testing['gs_cod']\n",
    "    Train_X = training['tags']\n",
    "    Train_Y = training['gs_cod']\n",
    "    Test_X_covariates = df.loc[Test_X.index]['age_yr']\n",
    "\n",
    "    return Test_X, Test_Y, Train_X, Train_Y, Test_X_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d46fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(Test_X, Test_Y, Train_X, Train_Y):\n",
    "    '''\n",
    "    takes vectors of test and train data\n",
    "    returns TF-IDF embeddings X as scipy matrix\n",
    "    '''\n",
    "    \n",
    "    Encoder = LabelEncoder()\n",
    "    Train_Y = Encoder.fit_transform(Train_Y)\n",
    "    Test_Y = Encoder.fit_transform(Test_Y)\n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "    Tfidf_vect.fit(Train_X)\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "    \n",
    "    return Train_X_Tfidf, Test_X_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59bb3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y):\n",
    "    '''\n",
    "    takes in vectors of X embeddings and Y labels for training and testing data\n",
    "    fits a naive bayes classifier and makes predictions on the test set\n",
    "    returns accuracy and weighted F1 scores as doubles\n",
    "    '''\n",
    "    \n",
    "    # fit the training dataset on the NB classifier\n",
    "    NB = naive_bayes.MultinomialNB()\n",
    "    NB.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_NB = list(NB.predict(Test_X_Tfidf))\n",
    "    \n",
    "    # return as integer embeddings instead of as strings\n",
    "    predictions_NB = string_to_embedding(predictions_NB)\n",
    "    Test_Y = string_to_embedding(Test_Y)\n",
    "        \n",
    "    # Use accuracy_score and f1_score functions to get the accuracy\n",
    "    NB_accuracy = accuracy_score(predictions_NB, Test_Y)\n",
    "    NB_weighted_f1 = f1_score(predictions_NB, Test_Y, average='weighted')\n",
    "    \n",
    "    return NB_accuracy, NB_weighted_f1, predictions_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "134c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y):\n",
    "    '''\n",
    "    takes in vectors of X embeddings and Y labels for training and testing data\n",
    "    fits a SVM classifier and makes predictions on the test set\n",
    "    returns accuracy and weighted F1 scores as doubles\n",
    "    '''\n",
    "    \n",
    "    # fit the training dataset on the SVM classifier\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_SVM = list(SVM.predict(Test_X_Tfidf))\n",
    "    \n",
    "    # return as integer embeddings instead of as strings\n",
    "    predictions_SVM = string_to_embedding(predictions_SVM)\n",
    "    Test_Y = string_to_embedding(Test_Y)\n",
    "    \n",
    "    # Use accuracy_score and f1_score functions to get the accuracy\n",
    "    SVM_accuracy = accuracy_score(predictions_SVM, Test_Y)\n",
    "    SVM_weighted_f1 = f1_score(predictions_SVM, Test_Y, average='weighted')\n",
    "    \n",
    "    return SVM_accuracy, SVM_weighted_f1, predictions_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7e70aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y):\n",
    "    '''\n",
    "    takes in vectors of X embeddings and Y labels for training and testing data\n",
    "    fits a KNN classifier and makes predictions on the test set\n",
    "    returns accuracy and weighted F1 scores as doubles\n",
    "    '''\n",
    "    \n",
    "    # Applying k = 3, default Minkowski distance metrics\n",
    "    KNN = KNeighborsClassifier(n_neighbors=8, weights='distance', metric='cosine')\n",
    "    KNN.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions_KNN = list(KNN.predict(Test_X_Tfidf))\n",
    "    \n",
    "    # return as integer embeddings instead of as strings\n",
    "    predictions_KNN = string_to_embedding(predictions_KNN)\n",
    "    Test_Y = string_to_embedding(Test_Y)\n",
    "\n",
    "    # Use accuracy_score and f1_score functions to get the accuracy\n",
    "    KNN_accuracy = accuracy_score(predictions_KNN, Test_Y)\n",
    "    KNN_weighted_f1 = f1_score(predictions_KNN, Test_Y, average='weighted')\n",
    "    \n",
    "    return KNN_accuracy, KNN_weighted_f1, predictions_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c63edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_results(NB_accuracy, NB_weighted_f1, SVM_accuracy, SVM_weighted_f1, KNN_accuracy, KNN_weighted_f1):\n",
    "    '''\n",
    "    combines accuracy and weighted F1 scores from NB, SVM and KNN into a dictionary for plotting\n",
    "    '''\n",
    "    \n",
    "    accuracy_scores = {'NB': NB_accuracy, 'SVM': SVM_accuracy, 'KNN': KNN_accuracy}\n",
    "    weighted_f1_scores = {'NB': NB_weighted_f1, 'SVM': SVM_weighted_f1, 'KNN': KNN_weighted_f1}\n",
    "    \n",
    "    return accuracy_scores, weighted_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f30bf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(accuracy_scores, weighted_f1_scores):\n",
    "    '''\n",
    "    this takes scores from compiled results dict and returns a ggplot object comparing the results. \n",
    "    '''\n",
    "    \n",
    "    ## Plot Differences\n",
    "    models = ['NB', 'KNN', 'SVM']\n",
    "    accuracy_scores = accuracy_scores\n",
    "    weighted_f1_scores = weighted_f1_scores\n",
    "\n",
    "    # Plotting\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(models))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar1 = ax.bar(index, list(accuracy_scores.values()), bar_width, label='Accuracy')\n",
    "    bar2 = ax.bar(index + bar_width, list(weighted_f1_scores.values()), bar_width, label='Weighted F1')\n",
    "\n",
    "    ax.set_xlabel('Classifier')\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('VA COD Classification with Classic NLP')\n",
    "    ax.set_xticks(index + bar_width / 2)\n",
    "    ax.set_xticklabels(models)\n",
    "    # Setting y-axis limits\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.legend()\n",
    "\n",
    "    # Adding labels on top of the bars\n",
    "    for i, v in enumerate(list(accuracy_scores.values())):\n",
    "        ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', color='black', fontweight='bold')\n",
    "\n",
    "    for i, v in enumerate(list(weighted_f1_scores.values())):\n",
    "        ax.text(i + bar_width, v + 0.01, f'{v:.2f}', ha='center', va='bottom', color='black', fontweight='bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11c1cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNL_predict_on_cov(predictions_NB, predictions_SVM, predictions_KNN):\n",
    "    '''\n",
    "    This takes in arrays of predicted COD embeddings from the NLP classifiers\n",
    "    prints summaries of the estimated coef, SE, p-val, and confidence intervals \n",
    "    '''\n",
    "    # Add a constant term to the features for the intercept\n",
    "    Test_X_covariates_constant = sm.add_constant(np.array(Test_X_covariates).reshape(-1,1))\n",
    "\n",
    "    # Fit the multinomial logistic regression models using Statsmodels\n",
    "\n",
    "    NB_baseline = sm.MNLogit(predictions_NB, Test_X_covariates_constant, check_rank=True).fit(method='bfgs')\n",
    "    SVM_baseline = sm.MNLogit(predictions_SVM, Test_X_covariates_constant, check_rank=True).fit(method='bfgs')\n",
    "    KNN_baseline = sm.MNLogit(predictions_KNN, Test_X_covariates_constant, check_rank=True).fit(method='bfgs')\n",
    "    \n",
    "    print(NB_baseline.summary())\n",
    "    print(SVM_baseline.summary())\n",
    "    print(KNN_baseline.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a1c33",
   "metadata": {},
   "source": [
    "## Loop through regions and run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ede84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dfs\n",
    "training_dfs = [\n",
    "    train_ex_mexico,\n",
    "    train_ex_ap,\n",
    "    train_ex_dar, \n",
    "    train_ex_pemba, \n",
    "    train_ex_bohol, \n",
    "    train_ex_up]\n",
    "\n",
    "# combine labeled and unlabeled testing data\n",
    "test_mexico_combined = pd.concat([test_mexico, val_mexico])\n",
    "test_ap_combined = pd.concat([test_ap, val_ap])\n",
    "test_dar_combined = pd.concat([test_dar, val_dar])\n",
    "test_pemba_combined = pd.concat([test_pemba, val_pemba])\n",
    "test_bohol_combined = pd.concat([test_bohol, val_bohol])\n",
    "test_up_combined = pd.concat([test_up, val_up])\n",
    "    \n",
    "testing_dfs = [\n",
    "    test_mexico_combined,\n",
    "    test_ap_combined,\n",
    "    test_dar_combined,\n",
    "    test_pemba_combined,\n",
    "    test_bohol_combined,\n",
    "    test_up_combined\n",
    "]\n",
    "\n",
    "regions = [\n",
    "    'mexico',\n",
    "    'ap',\n",
    "    'dar',\n",
    "    'pemba',\n",
    "    'bohol',\n",
    "    'up'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ccc4e9e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ebe1032d5a4f4caa58e6b9c4cb645f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic NLP Pipeline with mexico left out.\n",
      "(5457, 12)\n",
      "(1306, 12)\n",
      "Classic NLP Pipeline with ap left out.\n",
      "(5619, 12)\n",
      "(1144, 12)\n",
      "Classic NLP Pipeline with dar left out.\n",
      "(5199, 12)\n",
      "(1564, 12)\n",
      "Classic NLP Pipeline with pemba left out.\n",
      "(6503, 12)\n",
      "(260, 12)\n",
      "Classic NLP Pipeline with bohol left out.\n",
      "(5654, 12)\n",
      "(1109, 12)\n",
      "Classic NLP Pipeline with up left out.\n",
      "(5383, 12)\n",
      "(1380, 12)\n"
     ]
    }
   ],
   "source": [
    "for train_df, test_df, region in tqdm(zip(training_dfs, testing_dfs, regions)):\n",
    "    \n",
    "    print(f\"Classic NLP Pipeline with {region} left out.\")\n",
    "    print(train_df.shape)\n",
    "    print(test_df.shape)\n",
    "\n",
    "    # split into training and testing\n",
    "    Test_X, Test_Y, Train_X, Train_Y, Test_X_covariates = split_data(testing=test_df, training=train_df)\n",
    "        \n",
    "    # create embeddings from narratives text\n",
    "    Train_X_Tfidf, Test_X_Tfidf = embeddings(Test_X, Test_Y, Train_X, Train_Y)\n",
    "    \n",
    "    # Fit and predict with Naive Bayes\n",
    "    NB_accuracy, NB_weighted_f1, predictions_NB = NB_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y)\n",
    "    \n",
    "    # Fit and predict with SVM\n",
    "    SVM_accuracy, SVM_weighted_f1, predictions_SVM = SVM_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y)\n",
    "    \n",
    "    # Fit and predict with KNN\n",
    "    KNN_accuracy, KNN_weighted_f1, predictions_KNN = KNN_classifier(Train_X_Tfidf, Test_X_Tfidf, Train_Y, Test_Y)\n",
    "    \n",
    "    # compile the results from the three models\n",
    "    accuracy_scores, weighted_f1_scores = compile_results(NB_accuracy, \n",
    "                                                          NB_weighted_f1, \n",
    "                                                          SVM_accuracy, \n",
    "                                                          SVM_weighted_f1, \n",
    "                                                          KNN_accuracy, \n",
    "                                                          KNN_weighted_f1)\n",
    "    \n",
    "    # print out results to csv\n",
    "    predictions_df = pd.DataFrame({'Y': string_to_embedding(Test_Y),\n",
    "                                   'X_unlabeled': Test_X_covariates,\n",
    "                                   'Yhat_NB': predictions_NB,\n",
    "                                   'Yhat_SVM': predictions_SVM, \n",
    "                                   'Yhat_KNN': predictions_KNN})\n",
    "    \n",
    "    predictions_df.to_csv(f'../../classic_predictions_ex_{region}.csv', index=False)\n",
    "    # plot the results\n",
    "#     plot_compare(accuracy_scores, weighted_f1_scores)\n",
    "    \n",
    "    # MNlogit regress on covariates using predicted cause of death from each model and print summary\n",
    "#     MNL_predict_on_cov(predictions_NB, predictions_SVM, predictions_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc21bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528e5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
